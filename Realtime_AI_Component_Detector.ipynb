{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Realtime-AI-Component-Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1c2McT7Vuzl_EPNWCnoxBiIvHd1lfu6we",
      "authorship_tag": "ABX9TyOLSx9D9vhy5q36Wxzz0dx5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sasagackie/Realtime-A.I.-Object-Detector/blob/master/Realtime_AI_Component_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZx60FhYQLXh",
        "colab_type": "text"
      },
      "source": [
        "# **Preface**\n",
        "This note is to describe how to make a practical trained CNN model\n",
        "that can deliver high detection accuracy in recognition of electronic\n",
        "components. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a46VWQ1MoNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Below would be executed only when you mount the directory on your local PC.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "# the project's folder\n",
        "%cd /gdrive/'My Drive'/object_detection\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B95dlGeyJA1x",
        "colab_type": "text"
      },
      "source": [
        "# **Prep Before the Training**\n",
        "\n",
        "1) Download or prepare images you want to let your model learn.\n",
        "\n",
        "2) Label objects on your images. This will output .xml file for each image.\n",
        "\n",
        "3) Make ***object_detection*** directory wherever you want on your local PC.\n",
        "\n",
        "4) With *Google Colab*, mount the ***object_detection*** directory on your local PC under the /content/drive/My Drive/ directory, so that you can handle your files under the directory from your local PC. This will make the full path to the ***object_detection*** directory on *Google Colab*, like ***/content/drive/My Drive/object_detection***.\n",
        "\n",
        "5) Make ***data*** directory under the ***object_detection*** directory.\n",
        "\n",
        "6) Make ***annotations*** and ***images*** directories under the ***data*** directory.\n",
        "\n",
        "7) Copy .xml files you created at **2)** under the ***object_detection/data/annotations*** directory and the image files you gathered under the ***object_detection/data/images*** directory.\n",
        "\n",
        "8) Make ***test_labels*** and ***train_labels*** directories under the ***object_detection/data/*** directory.\n",
        "\n",
        "9) Split 20% of total .xml files under the ***test_labesl*** directory and the rest of .xml files under the ***train_labels*** directory.\n",
        "You can make it randomly by doing like below:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QpH75yKRQUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Command Example below is for the 2000 total .xml files. You can make an adjustment\n",
        "# by changing the number for the ratio between the training and the test, \n",
        "# according to the number of total .xml files you have.\n",
        "# Lists the files inside 'annotations' in a random order\n",
        "# (not really random, by their hash value instead).\n",
        "\n",
        "\n",
        "# Move the current dir to /content/drive/My Drive/object_detection/data/\n",
        "cd /content/drive/My\\ Drive/object_detection/data/\n",
        "\n",
        "# Below is to check how many .xml files you currently have.\n",
        "ls annotations/* | wc -l\n",
        "\n",
        "# Moves the first 400/2000 labels (20% of the labels) to the testing dir: `test_labels`\n",
        "!ls annotations/* | sort -R | head -400 | xargs -I{} mv {} test_labels/\n",
        "\n",
        "\n",
        "# Moves the rest of labels '1600' labels to the training dir: `train_labels`\n",
        "!ls annotations/* | xargs -I{} mv {} train_labels/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZUb410qM6V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the current dir.\n",
        "cd /content/drive/My\\ Drive/object_detection/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbk7dX1KNHuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing the packages. They don't get pre-installed by default.\n",
        "# Install them by running:\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8SwoyDMR4fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's select the TensorFlow version 1 rather than version 2\n",
        "# because of the less dipendency issues.\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s7xwXsmSGUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries:\n",
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import glob\n",
        "import shutil\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import cv2 \n",
        "\n",
        "from PIL import Image\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "from google.colab import files\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiLNOnq6Nzmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This script outputs two csv files \n",
        "# by reading the .xml files under the train_labels and the test_labels dir.\n",
        "# Change the current directory\n",
        "!cd /content/drive/My\\ Drive/object_detection/data\n",
        "\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text, # Del .jpg\n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_hiTHMYgETP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloads the deep learning models under the object_detection directory.\n",
        "# it will make a directory under the object_detection dir, called models.\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSL_JNlnCN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/object_detection/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvifX05uN8NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compils the proto buffers\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# exports PYTHONPATH environment var with research and slim paths\n",
        "os.environ['PYTHONPATH'] += ':./:./slim/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9WPt2I7ONPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the tf_slim\n",
        "!pip install --upgrade tf_slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-tcLhJxOYxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing the model builder\n",
        "!python3 object_detection/builders/model_builder_test.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ENjZDj1rMQd",
        "colab_type": "text"
      },
      "source": [
        "# **Generating the TFRecord**\n",
        "Based on the csv files you have created above, the script below creates two binary files, named ***train_labels.record*** and ***test_labels.record***.\n",
        "Before executing it, you make sure that:\n",
        "\n",
        "1) The current directory is ***object_detection/models/research/***.\n",
        "\n",
        "2) The ***DATA_BASE_PATH*** in the script is the same as the path to your ***data*** directory.\n",
        "\n",
        "3) You have all ***classes*** listed under the ***class_text_to_int*** function in the script.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcSyl3xhOzUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "from object_detection.utils import dataset_util\n",
        "%cd /content/drive/My Drive/object_detection/models\n",
        "\n",
        "DATA_BASE_PATH = '/content/drive/My Drive/object_detection/data/'\n",
        "image_dir = DATA_BASE_PATH +'images/'\n",
        "\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "  if row_label == 'Capacitor':\n",
        "    return 1\n",
        "  elif row_label == 'Diode':\n",
        "    return 1\n",
        "  elif row_label == 'IC':\n",
        "    return 1\n",
        "  elif row_label == 'Inductor':\n",
        "    return 1\n",
        "  elif row_label == 'LED':\n",
        "    return 1\n",
        "  elif row_label == 'Potentiometer':\n",
        "    return 1\n",
        "  elif row_label == 'Relay':\n",
        "    return 1\n",
        "  elif row_label == 'Resistor':\n",
        "    return 1\n",
        "  elif row_label == 'Transformer':\n",
        "    return 1\n",
        "  elif row_label == 'Transistor':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def split(df, group):\n",
        "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
        "\t\tgb = df.groupby(group)\n",
        "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "\t\t\t\tencoded_jpg = fid.read()\n",
        "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\t\timage = Image.open(encoded_jpg_io)\n",
        "\t\twidth, height = image.size\n",
        "\n",
        "\t\tfilename = group.filename.encode('utf8')\n",
        "\t\timage_format = b'jpg'\n",
        "\t\txmins = []\n",
        "\t\txmaxs = []\n",
        "\t\tymins = []\n",
        "\t\tymaxs = []\n",
        "\t\tclasses_text = []\n",
        "\t\tclasses = []\n",
        "\n",
        "\t\tfor index, row in group.object.iterrows():\n",
        "\t\t\t\txmins.append(row['xmin'] / width)\n",
        "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
        "\t\t\t\tymins.append(row['ymin'] / height)\n",
        "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
        "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
        "\n",
        "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
        "\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
        "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
        "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t\t}))\n",
        "\t\treturn tf_example\n",
        "\n",
        "for csv in ['train_labels', 'test_labels']:\n",
        "  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n",
        "  path = os.path.join(image_dir)\n",
        "  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "      tf_example = create_tf_example(group, path)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "    \n",
        "  writer.close()\n",
        "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
        "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEI-IDXq7woG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some models to train on\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "    },\n",
        "}\n",
        "\n",
        "# Select a model from `MODELS_CONFIG`.\n",
        "# I chose ssd_mobilenet_v2 for this project, you could choose any\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "#selected_model = 'faster_rcnn_inception_v2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSqXe0eF74Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the distination folder where the model will be saved\n",
        "#change this if you have a different working dir\n",
        "DEST_DIR = '/content/drive/My Drive/object_detection/models/research/pretrained_model'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "#selecting the model\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "#creating the downlaod link for the model selected\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "#checks if the model has already been downloaded, download it otherwise\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "#unzipping the model and extracting its content\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# creating an output file to save the model while training\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD5frP1JA8Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move to the research dir.\n",
        "cd /content/drive/My\\ Drive/object_detection/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0cyE5WQBFfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = \"training/\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "#The link to tensorboard.\n",
        "#works after the training starts.\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJEfNrsudhkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the log directry\n",
        "!tensorboard --logdir=/content/drive/My\\ Drive/object_deteion/models/research/training/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOeGGJAnBvFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The main training script.\n",
        "# It has to be executed at /content/drive/My Drive/object_detection/models/research\n",
        "# Before the execution, make sure that all the images are RGB. \n",
        "# Delete the non-RGB images from the *images* directory and \n",
        "# the corresponding record from both *test_labels.csv* and *train_labels.csv*,\n",
        "# then, generate the TFRecord again.\n",
        "!python3 object_detection/model_main.py \\\n",
        "    --pipeline_config_path=/content/drive/My\\ Drive/object_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n",
        "    --model_dir=training/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMkjG6SDXtWj",
        "colab_type": "text"
      },
      "source": [
        "# **Extracting Frozen Model**\n",
        "For the webcam inference, you need to extract the file, named ***frozen_inference_graph.pb***, and place it on your computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCDl_LFJzStK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the dir where the model will be saved\n",
        "# output_directory should be changed to the existing dir for a new frozen model.\n",
        "output_directory = './fine_tuned_model_07'\n",
        "\n",
        "lst = os.listdir('training')\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join('training', last_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9clhDQJs8QGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exporting the latest model\n",
        "!python /content/drive/'My Drive'/object_detection/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=/content/drive/My\\ Drive/object_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lOtcCvZZO40",
        "colab_type": "text"
      },
      "source": [
        "# **Webcam Inference**\n",
        "\n",
        "Place the three files below at the same directry on your computer:<br>\n",
        "\n",
        "\n",
        "\n",
        "1.   ***frozen_inference_graph.pb***\n",
        "2.   ***label_map.pbtxt***\n",
        "3.   ***live_inference.py***\n",
        "\n",
        "You can copy and paste the live_inference.py code below.\n",
        "Then, edit the filename at \"PATH_TO_FROZEN_GRAPH =\" in the live_inference.py as you want.\n",
        "<br>\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from object_detection.utils import label_map_util \n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from PIL import ImageFont\n",
        "\n",
        "# path to the frozen graph:\n",
        "PATH_TO_FROZEN_GRAPH = 'frozen_inference_graph.pb'\n",
        "\n",
        "# path to the label map\n",
        "PATH_TO_LABEL_MAP = 'label_map.pbtxt'\n",
        "\n",
        "# number of classes \n",
        "NUM_CLASSES = 90\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "#reads the frozen graph\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABEL_MAP)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Detection\n",
        "with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "        while True:\n",
        "            # Read frame from camera\n",
        "            ret, image_np = cap.read()\n",
        "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "            # Image Font\n",
        "            ImageFont.truetype('./Arial.ttf', 30)\n",
        "            # Extract image tensor\n",
        "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "            # Extract detection boxes\n",
        "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "            # Extract detection scores\n",
        "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "            # Extract detection classes\n",
        "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "            # Extract number of detections\n",
        "            num_detections = detection_graph.get_tensor_by_name(\n",
        "                'num_detections:0')\n",
        "            # Actual detection.\n",
        "            (boxes, scores, classes, num_detections) = sess.run(\n",
        "                [boxes, scores, classes, num_detections],\n",
        "                feed_dict={image_tensor: image_np_expanded})\n",
        "            # Visualization of the results of a detection.\n",
        "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np,\n",
        "                np.squeeze(boxes),\n",
        "                np.squeeze(classes).astype(np.int32),\n",
        "                np.squeeze(scores),\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                line_thickness=8,\n",
        "                )\n",
        "        # Display output\n",
        "            cv2.imshow('Electronic Components Detector', cv2.resize(image_np, (1200, 800)))\n",
        "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                cv2.destroyAllWindows()\n",
        "\n",
        "                break\n",
        "\n",
        "```\n",
        "\n",
        "When you are ready, just execute the command on the terminal of your computer like below:\n",
        "\n",
        "\n",
        "```\n",
        "python live_inference.py\n",
        "```\n",
        "Then, you will soon see your webcam getting activated and the inference screen. Face your webcam to the circuit board and have fun!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbrqGXsOcIHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLRd7sCSWimg",
        "colab_type": "text"
      },
      "source": [
        "# **Detection Verification**\n",
        "The scripts below output the images with bounding boxes on components. You can feed some images you want to verify, then receive the output results with overlapped bounding boxes on components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haQCe6tEnI_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My\\ Drive/object_detection/models/research/object_detection/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs6gUxuUxe0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Swicth the Tensorflow v.1 and v.2.\n",
        "# Choose v.2 when you try the script below\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVhsYJE8dJTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This script verifies the input images and outputs the images with the bounding boxes as the detection.\n",
        "# Since this script works for all the jpg images in the directory you specify, \n",
        "# change the directory name for the input. The output images would be put in the same dir\n",
        "# with the suffix, \"-out.jpg\" following their original file name.\n",
        "\n",
        "# Go to cd /content/drive/My\\ Drive/object_detection/models/research/object_detection/\n",
        "# before do this.\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Import another utilites\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "# Main function\n",
        "def main(f):\n",
        "  # Path to frozen detection graph .pb file, which contains the model that is used\n",
        "  # for object detection. Change the fine name as needed.\n",
        "  PATH_TO_CKPT = '/content/drive/My Drive/object_detection/TestDir/frozen_inference_graph_03.pb'\n",
        "\n",
        "  # Path to label map file\n",
        "  PATH_TO_LABELS = '/content/drive/My Drive/object_detection/TestDir/label_map.pbtxt'\n",
        "\n",
        "  # Path to image (Change the file name needed to be verifieid.)\n",
        "  PATH_TO_IMAGE = f \n",
        "\n",
        "  # Number of classes the object detector can identify\n",
        "  NUM_CLASSES = 10 \n",
        "\n",
        "  # Load the label map.\n",
        "  label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "  categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "  category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "  # Load the TensorFlow model into memory.\n",
        "  detection_graph = tf.Graph()\n",
        "  with detection_graph.as_default():\n",
        "      od_graph_def = tf.compat.v1.GraphDef()\n",
        "      with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "          serialized_graph = fid.read()\n",
        "          od_graph_def.ParseFromString(serialized_graph)\n",
        "          tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "      sess = tf.Session(graph=detection_graph)\n",
        "\n",
        "  # Input tensor is the image\n",
        "  image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "  # Output tensors are the detection boxes, scores, and classes\n",
        "  detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "  # Each score represents level of confidence for each of the objects.\n",
        "  # The score is shown on the result image, together with the class label.\n",
        "  detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "  detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "  # Number of objects detected\n",
        "  num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "  # Load image using OpenCV and\n",
        "  image = cv2.imread(PATH_TO_IMAGE)\n",
        "  image_expanded = np.expand_dims(image, axis=0)\n",
        "\n",
        "  # Perform the actual detection by running the model with the image as input\n",
        "  (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections], feed_dict={image_tensor: image_expanded})\n",
        "\n",
        "  # Draw the results of the detection\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=8,\n",
        "          min_score_thresh=0.3)\n",
        "  # All the results have been drawn on image. Now display the image.\n",
        "  # cv2.imshow('Object detector', cv2.resize(image, (int(2592/2),int(1944/2))))\n",
        "\n",
        "  # # Press any key to close the image\n",
        "  # cv2.waitKey(0)\n",
        "\n",
        "  # # Clean up\n",
        "  # cv2.destroyAllWindows()\n",
        "  # Change the file name needed to be output.\n",
        "  cv2.imwrite(f + \"-out.jpg\", image)\n",
        "\n",
        "# Execute main()\n",
        "files = glob.glob(\"/content/drive/My Drive/object_detection/TestDir/TestImages02/*.jpg\")\n",
        "for jpg in files:\n",
        "  main(jpg)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}